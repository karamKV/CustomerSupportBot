{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e66f7cfa-b5cf-4c09-8031-961fb552aba2",
   "metadata": {},
   "source": [
    "# READ URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc871be-972c-4617-a605-284c9946bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6f4747-d00e-40dd-95fc-c7fb0331e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"url_list.txt\", 'r', encoding='utf-8') as file:\n",
    "    content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb923171-7749-4578-9de7-b9947cb029f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "content=content.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfcdf50-d9ad-4946-89ab-5add6c6c25e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "content=[item for item in content if len(item)>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02742be6-7be2-46c5-8286-17ae614f0bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def generate_hash(url):\n",
    "    return hashlib.sha256(url.encode('utf-8')).hexdigest()\n",
    "\n",
    "hashKeys=[]\n",
    "for item in content:\n",
    "    hashKeys.append(generate_hash(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc27771-c2b3-4062-9eb5-d8d628d8f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(content, hashKeys)), columns=['url', 'hashkey'])\n",
    "df.to_csv(\"mappedHashKeysToUrl.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c06b66-26d1-4558-a178-16386b4c4fdc",
   "metadata": {},
   "source": [
    "# CALL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0434a4-b302-4b1c-ba23-92b7011c9b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"mappedHashKeysToUrl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aec6067-2f02-4731-b8c4-13c287e7b593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import os\n",
    "\n",
    "def get_slm_response(url):\n",
    "    api_url = \"apiURL\"\n",
    "    auth_token = \"auth_token\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Basic {auth_token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    # payload = {\n",
    "    #     \"url\": url,  # Using the correct parameter name\n",
    "    # }\n",
    "    payload = {\n",
    "        \"content\": url,  # Using the correct parameter name\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(api_url, headers=headers, json=payload)\n",
    "        if response.status_code == 200:\n",
    "            return eval(response.content)['content']\n",
    "        else:\n",
    "            return f\"Error: Status code {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def generate_md_file(hashkey, content):\n",
    "    \"\"\"Generate markdown file with the given hashkey and content\"\"\"\n",
    "    # Create 'md_files' directory if it doesn't exist\n",
    "    os.makedirs('md_files', exist_ok=True)\n",
    "    \n",
    "    # Create and write to the markdown file\n",
    "    filename = f\"md_files/{hashkey}.md\"\n",
    "    try:\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing file {filename}: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc22d5a7-5546-4365-8bad-d40eb620c707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Main processing loop with progress bar\n",
    "# for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing URLs\"):\n",
    "#     try:\n",
    "#         # Get response from API\n",
    "#         response = get_slm_response(row['url'])\n",
    "        \n",
    "#         # Generate markdown file\n",
    "#         if response:\n",
    "#             success = generate_md_file(row['hashkey'], response)\n",
    "#             if not success:\n",
    "#                 print(f\"Failed to generate MD file for URL: {row['url']}\")\n",
    "#         else:\n",
    "#             print(f\"No response for URL: {row['url']}\")\n",
    "            \n",
    "#         # Optional: Add a small delay to prevent overwhelming the API\n",
    "#         time.sleep(0.5)\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing row {i}: {e}\")\n",
    "#         continue\n",
    "\n",
    "# print(\"Processing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cc752d-0964-42a6-b56d-8b7c5480c562",
   "metadata": {},
   "source": [
    "# RETRIEVER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbeb58f-23af-475f-8c4e-7f5f341d1fca",
   "metadata": {},
   "source": [
    "## Preparing Chunk DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec905a59-3181-49a3-b15f-4b1b86dd05ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "file_path = \"url_structure.json\"\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open(file_path, 'r') as file:\n",
    "    # Parse JSON data into a Python object\n",
    "    data = json.load(file)\n",
    "filtered_items_dict = {key: value for key, value in data['links'].items() if \"folder\" in key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd51e6fd-9563-491e-a1e1-2381990d0397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa843391-fafb-4fff-9bb1-3f6da1c5c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"mappedHashKeysToUrl.csv\")\n",
    "df_filtered=df[df['url'].isin(list(set(list(filtered_items_dict.keys()))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badbb779-2ef3-49fb-959b-b568ab209776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, row in tqdm(df_filtered.iterrows(), total=len(df_filtered), desc=\"Processing URLs\"):\n",
    "#     file_path=\"md_files/\"+row['hashkey']+\".md\"\n",
    "#     with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#         content = file.read()\n",
    "#     response=get_slm_response(content)\n",
    "#     df_filtered.at[i,'folder_name']=response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f900614-6c28-43dd-a666-8511d52729f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_filtered.to_csv(\"folderNamesMapping.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043b33b3-a7e7-4720-aa2f-4fd028372b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent=[]\n",
    "child=[]\n",
    "for k,v in data['links'].items():\n",
    "    for item in v:\n",
    "        parent.append(k)\n",
    "        child.append(item)\n",
    "dfParentChild = pd.DataFrame(list(zip(parent, child)), columns=['parentUrl', 'childUrl'])\n",
    "#dfParentChild.to_csv(\"parentChildURLMapping.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13bce6f-17fc-4389-b568-14610d573010",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered=pd.read_csv(\"folderNamesMapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc69877-4b3a-4252-ab9d-242c52fdc417",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(dfParentChild[['childUrl', 'parentUrl']], \n",
    "              left_on='url', \n",
    "              right_on='childUrl', \n",
    "              how='left')\n",
    "df['folder'] = df['parentUrl']\n",
    "df = df.drop(['childUrl', 'parentUrl'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf2d5d0-b80e-460f-8fd6-e6b33ccc3110",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCategoryUrls = df[df['url'].str.contains(\"{patternString}\") & df['url'].str.split('/').str[-1].str.len().eq(11) & ~df['url'].str.contains('folders')]\n",
    "for i, row in tqdm(dfCategoryUrls.iterrows(), total=len(dfCategoryUrls), desc=\"Processing URLs\"):\n",
    "    file_path=\"md_files/\"+row['hashkey']+\".md\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    response=get_slm_response(content)\n",
    "    dfCategoryUrls.at[i,'CategoryName']=response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5f50fd-7913-4fe2-bede-5c5d3bebacc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfCategoryUrls.to_csv(\"CategoryURl.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eef51bc-1574-432c-9615-e8bd28ea26f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"csvWithFolderNames.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04541fd2-8adc-480e-847c-8dfeb331036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_category(url, df_parent_child, category_urls):\n",
    "    # First level check - direct parent in category URLs\n",
    "    temp = df_parent_child[df_parent_child['childUrl'] == url]\n",
    "    \n",
    "    if not temp.empty:\n",
    "        # Check if any direct parent is in category URLs\n",
    "        if any(parent in category_urls for parent in temp['parentUrl']):\n",
    "            return temp[temp['parentUrl'].isin(category_urls)]['parentUrl'].iloc[0]\n",
    "        \n",
    "        # If not, check folder parents\n",
    "        folder_parents = temp[temp['parentUrl'].str.contains('folder')]['parentUrl']\n",
    "        \n",
    "        if not folder_parents.empty:\n",
    "            # Second level check for each folder parent\n",
    "            for folder_url in folder_parents:\n",
    "                temp2 = df_parent_child[df_parent_child['childUrl'] == folder_url]\n",
    "        \n",
    "                \n",
    "                if any(parent in category_urls for parent in temp2['parentUrl']):\n",
    "                    return temp2[temp2['parentUrl'].isin(category_urls)]['parentUrl'].iloc[0]\n",
    "    \n",
    "    return None\n",
    "\n",
    "# # Test with a single URL first\n",
    "# test_url = df['url'].iloc[2]\n",
    "# result = find_category(test_url, dfParentChild, set(dfCategoryUrls['url']))\n",
    "\n",
    "\n",
    "#If the test looks good, then apply to full DataFrame\n",
    "df['category'] = df['url'].progress_apply(\n",
    "    lambda x: find_category(x, dfParentChild, set(dfCategoryUrls['url']))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a9a763-a799-4e7c-8b5f-dbf9d81a5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r in df.iterrows():\n",
    "    for i_,r_ in dfCategoryUrls.iterrows():\n",
    "        if r['category']==r_['url']:\n",
    "            df.at[i,\"CategoryName\"]=r_['CategoryName'].split(\"(\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27afd55e-7c66-430a-8462-9b54b742d1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r in df.iterrows():\n",
    "    for i_,r_ in df_filtered.iterrows():\n",
    "        if r['folder']==r_['url']:\n",
    "            df.at[i,\"FolderName\"]=r_['folder_name'].split(\"(\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caefa68-ded0-4f0e-b381-87a52e040c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"FinalMappingChunkData.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4aa5c1-fafb-480a-befd-16add514287f",
   "metadata": {},
   "source": [
    "## CHUNKING MODIFIED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba612180-b119-4825-94a1-f048b5af0f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r in tqdm(df.iterrows()):\n",
    "    file_path=\"md_files/\"+r['hashkey']+\".md\"\n",
    "    hashkey=r['hashkey']\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        if len(content)>100:\n",
    "            content=content.split(\"Was this article helpful?\")[0]\n",
    "            content=content.split(\"MARKDOWN CONTENT\")[1]\n",
    "    response = get_slm_response(content)\n",
    "    filename = f\"md_files_modified/{hashkey}.md\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fe1127-f2aa-47f9-8ff9-7567cfac9bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9c4b78-cdd8-48fb-9a3c-2aa774a12942",
   "metadata": {},
   "source": [
    "## INDEXING CHUNKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c1ec9e-e3cf-4ced-8ec8-a2a18eacc69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"FinalMappingChunkData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b628da5-d69f-48b5-a5e6-6942d3c36247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from langchain.schema import Document\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "#from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "#from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "import requests\n",
    "\n",
    "import io\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f83786-6ca0-4c5a-9824-cf707c7b72d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a916187-f507-47dd-8755-25995f484d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata=[]\n",
    "chunks=[]\n",
    "for i,r in df.iterrows():\n",
    "    item={}\n",
    "    item['url']=r['url']\n",
    "    item['Category']=r['CategoryName']\n",
    "    item['Folder']=r['FolderName']\n",
    "    file_path=\"md_files_modified//\"+r['hashkey']+\".md\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        chunk=\"URL: \\n\"+r['url']+\"\\n ------ CONTENT ------ \\n\"+ content\n",
    "    metadata.append(item)\n",
    "    chunks.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ad33d0-74b2-4575-bee2-892e64f7dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAKING LANGCHAIN DOCUMENT CLASS\n",
    "docs = []\n",
    "for item in range(len(df)):\n",
    "    \n",
    "    content = item\n",
    "    document = Document(page_content=chunks[item],metadata=metadata[item])\n",
    "    docs.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386e7de5-f3aa-4a3a-a30d-a3b6a3857748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Initialize FAISS vector store with GPU\n",
    "vectorstore = FAISS.from_documents(documents=docs, embedding=OpenAIEmbeddings(model=\"text-embedding-3-large\"))\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Initialize the Mistral language model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86adbb1-1855-49cd-9e8b-33d7fc5a953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.save_local('indexes-updated-chunks-summarized/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c617870a-f394-4a13-b70a-e02a32073769",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# VALIDATION DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70e28bd-a881-4419-8cdd-5d6d02fa4179",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfValidation=pd.read_csv(\"DS_Task_ValSet.csv\")\n",
    "def getResponse(query):\n",
    "    api_url = \"apiURL\"\n",
    "    auth_token = \"authToken\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Basic {auth_token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    payload = {\n",
    "        \"query\": query,  # Using the correct parameter name\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(api_url, headers=headers, json=payload)\n",
    "        if response.status_code == 200:\n",
    "            return eval(response.content)\n",
    "        else:\n",
    "            return f\"Error: Status code {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeeb7c5-f5a3-4c7c-b085-c92cc2ce1352",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r in tqdm(dfValidation.iterrows()):\n",
    "    query=r['Query']\n",
    "    response=getResponse(query)\n",
    "    if response['content']:\n",
    "        dfValidation.at[i,'answer']=response['content']\n",
    "    try:\n",
    "        dfValidation.at[i,'metadata']=response['metadata']\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3307c818-5563-42f1-8fac-8bce80e1f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfValidation.to_csv(\"ValidationResultsAgentic.csv\",index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
